{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kaggle import data, nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv = data.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>tags</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How can I get chewy chocolate chip cookies?</td>\n",
       "      <td>My chocolate chips cookies are always too cris...</td>\n",
       "      <td>baking cookies texture</td>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How should I cook bacon in an oven?</td>\n",
       "      <td>I've heard of people cooking bacon in an oven ...</td>\n",
       "      <td>oven cooking-time bacon</td>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the difference between white and brown...</td>\n",
       "      <td>I always use brown extra large eggs, but I can...</td>\n",
       "      <td>eggs</td>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What is the difference between baking soda and...</td>\n",
       "      <td>And can I use one in place of the other in cer...</td>\n",
       "      <td>substitutions please-remove-this-tag baking-so...</td>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In a tomato sauce recipe, how can I cut the ac...</td>\n",
       "      <td>It seems that every time I make a tomato sauce...</td>\n",
       "      <td>sauce pasta tomatoes italian-cuisine</td>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0        How can I get chewy chocolate chip cookies?   \n",
       "1                How should I cook bacon in an oven?   \n",
       "2  What is the difference between white and brown...   \n",
       "3  What is the difference between baking soda and...   \n",
       "4  In a tomato sauce recipe, how can I cut the ac...   \n",
       "\n",
       "                                             content  \\\n",
       "0  My chocolate chips cookies are always too cris...   \n",
       "1  I've heard of people cooking bacon in an oven ...   \n",
       "2  I always use brown extra large eggs, but I can...   \n",
       "3  And can I use one in place of the other in cer...   \n",
       "4  It seems that every time I make a tomato sauce...   \n",
       "\n",
       "                                                tags file_name  \n",
       "0                             baking cookies texture   cooking  \n",
       "1                            oven cooking-time bacon   cooking  \n",
       "2                                               eggs   cooking  \n",
       "3  substitutions please-remove-this-tag baking-so...   cooking  \n",
       "4               sauce pasta tomatoes italian-cuisine   cooking  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# vec=CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tags=vec.fit_transform(csv['tags']).todense()\n",
    "# tags=pd.DataFrame(tags, columns=vec.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- CC\tcoordinating conjunction\n",
    "- CD\tcardinal digit\n",
    "- DT\tdeterminer\n",
    "- EX\texistential there (like: \"there is\" ... think of it like \"there exists\")\n",
    "- FW\tforeign word\n",
    "- IN\tpreposition/subordinating conjunction\n",
    "- JJ\tadjective\t'big'\n",
    "- JJR\tadjective, comparative\t'bigger'\n",
    "- JJS\tadjective, superlative\t'biggest'\n",
    "- LS\tlist marker\t1)\n",
    "- MD\tmodal\tcould, will\n",
    "- NN\tnoun, singular 'desk'\n",
    "- NNS\tnoun plural\t'desks'\n",
    "- NNP\tproper noun, singular\t'Harrison'\n",
    "- NNPS\tproper noun, plural\t'Americans'\n",
    "- PDT\tpredeterminer\t'all the kids'\n",
    "- POS\tpossessive ending\tparent's\n",
    "- PRP\tpersonal pronoun\tI, he, she\n",
    "- PRPS\tpossessive pronoun\tmy, his, hers\n",
    "- RB\tadverb\tvery, silently,\n",
    "- RBR\tadverb, comparative\tbetter\n",
    "- RBS\tadverb, superlative\tbest\n",
    "- RP\tparticle\tgive up\n",
    "- TO\tto\tgo 'to' the store.\n",
    "- UH\tinterjection\terrrrrrrrm\n",
    "- VB\tverb, base form\ttake\n",
    "- VBD\tverb, past tense\ttook\n",
    "- VBG\tverb, gerund/present participle\ttaking\n",
    "- VBN\tverb, past participle\ttaken\n",
    "- VBP\tverb, sing. present, non-3d\ttake\n",
    "- VBZ\tverb, 3rd person sing. present\ttakes\n",
    "- WDT\twh-determiner\twhich\n",
    "- WP\twh-pronoun\twho, what\n",
    "- WPS\tpossessive wh-pronoun\twhose\n",
    "- WRB\twh-abverb\twhere, when"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, PunktSentenceTokenizer\n",
    "from nltk import word_tokenize, pos_tag\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "title1 = csv.iloc[0, 0]\n",
    "title2 = csv.iloc[1, 0]\n",
    "title3 = csv.iloc[2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentence1 = csv.iloc[0, 1]\n",
    "sentence2 = csv.iloc[1, 1]\n",
    "sentence3 = csv.iloc[2, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tags1 = csv.iloc[0, 2]\n",
    "tags2 = csv.iloc[1, 2]\n",
    "tags3 = csv.iloc[2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print sentence2, \"\\n\"\n",
    "# print tags2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# tokenizer = PunktSentenceTokenizer(sentence1)\n",
    "# tokenized = tokenizer.tokenize(sentence2)\n",
    "# tokenized = sent_tokenize(sentence2, language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"long_stopwords.txt\") as f:\n",
    "    stopwords = [word for line in f for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def break_list_of_tags(list_of_tags):\n",
    "    unique_tags = set()\n",
    "    for tagline in list_of_tags:\n",
    "        for word in tagline.split(\" \"):\n",
    "            if word not in unique_tags:\n",
    "                unique_tags.add(word)\n",
    "    return list(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = list(csv.tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(values):\n",
    "    output = []\n",
    "    seen = set()\n",
    "    for value in values:\n",
    "        # If value has not been encountered yet,\n",
    "        # ... add it to both list and set.\n",
    "        if value not in seen:\n",
    "            output.append(value)\n",
    "            seen.add(value)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def process_content(sentence, stopwords, all_tags):\n",
    "#     tokens = sent_tokenize(sentence, language='english')\n",
    "    \n",
    "#     cp = nltk.RegexpParser(r\"\"\"chunk: {<NNP>*<NN>*}\"\"\")\n",
    "#     chunks=[]\n",
    "#     for sent in tokens:\n",
    "#         tree = cp.parse(pos_tag(word_tokenize(sent)))\n",
    "#         for subtree in tree.subtrees():\n",
    "#             if subtree.label() == 'chunk': \n",
    "#                 chunks.append(subtree)\n",
    "                \n",
    "# #     return chunks\n",
    "#     tags=[]\n",
    "#     for tree in chunks:\n",
    "#         if len(tree.leaves()) == 1:\n",
    "#             if tree.leaves()[0][0] not in stopwords:\n",
    "#                 tag = tree.leaves()[0][0]\n",
    "#                 if tag in all_tags:\n",
    "#                     tags.append( tag)\n",
    "#         else:\n",
    "#             tags.append(\"-\".join([t[0] for t in tree.leaves()]))\n",
    "#     tags = remove_duplicates(tags)\n",
    "#     return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_content(sentence, stopwords, all_tags):\n",
    "    tokens = sent_tokenize(sentence, language='english')\n",
    "    \n",
    "    cp = nltk.RegexpParser(r\"\"\"chunk: {<NNP>*<NN>*}\"\"\")\n",
    "    chunks=[]\n",
    "    for sent in tokens:\n",
    "        tree = cp.parse(pos_tag(word_tokenize(sent)))\n",
    "        for subtree in tree.subtrees():\n",
    "            if subtree.label() == 'chunk': \n",
    "                chunks.append(subtree)\n",
    "                \n",
    "#     return chunks\n",
    "    tags=[]\n",
    "    for tree in chunks:\n",
    "        if len(tree.leaves()) == 1:\n",
    "            if tree.leaves()[0][0] not in stopwords: tags.append(tree.leaves()[0][0]) \n",
    "        else:\n",
    "            tags.append(\"-\".join([t[0] for t in tree.leaves()]))\n",
    "    tags\n",
    "    return remove_duplicates(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"kaggle/long_stopwords.txt\") as f:\n",
    "    stopwords = [word for line in f for word in line.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence1 = sentence1.replace(\"  \", \" \")\n",
    "sentence1 = sentence1.replace(\"Thank\", \"thank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I get chewy chocolate chip cookies? \n",
      "\n",
      "My chocolate chips cookies are always too crisp. How can I get chewy cookies, like those of Starbucks? thank you to everyone who has answered. So far the tip that had the biggest impact was to chill and rest the dough, however I also increased the brown sugar ratio and increased a bit the butter. Also adding maple syrup helped.  \n",
      "\n",
      "baking cookies texture\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'chocolate',\n",
       " u'impact',\n",
       " u'dough',\n",
       " u'brown-sugar-ratio',\n",
       " u'bit',\n",
       " u'butter',\n",
       " u'maple-syrup',\n",
       " u'chocolate-chip']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = process_content(\" \".join([sentence1, title1]), stopwords, tags)\n",
    "print title1, \"\\n\"\n",
    "print sentence1, \"\\n\"\n",
    "print tags1\n",
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I get chewy chocolate chip cookies? \n",
      "\n",
      "My chocolate chips cookies are always too crisp. How can I get chewy cookies, like those of Starbucks?  Thank you to everyone who has answered. So far the tip that had the biggest impact was to chill and rest the dough, however I also increased the brown sugar ratio and increased a bit the butter. Also adding maple syrup helped.   \n",
      "\n",
      "baking cookies texture\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'chocolate',\n",
       " u'dough',\n",
       " u'brown-sugar-ratio',\n",
       " u'butter',\n",
       " u'maple-syrup',\n",
       " u'chocolate-chip']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = process_content(\" \".join([sentence1, title1]), stopwords, tags)\n",
    "print title1, \"\\n\"\n",
    "print sentence1, \"\\n\"\n",
    "print tags1\n",
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How should I cook bacon in an oven? \n",
      "\n",
      "I've heard of people cooking bacon in an oven by laying the strips out on a cookie sheet. When using this method, how long should I cook the bacon for, and at what temperature?  \n",
      "\n",
      "oven cooking-time bacon\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'bacon', u'temperature', u'oven']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = process_content(\" \".join([sentence2, title2]), stopwords, tags)\n",
    "print title2, \"\\n\"\n",
    "print sentence2, \"\\n\"\n",
    "print tags2\n",
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# title3 = title3.replace(\"?\", '')\n",
    "# sentence3 = sentence3.replace(\"?\", '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the difference between white and brown eggs? \n",
      "\n",
      "I always use brown extra large eggs, but I can't honestly say why I do this other than habit at this point. Are there any distinct advantages or disadvantages like flavor, shelf life, etc?  \n",
      "\n",
      "eggs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'flavor', u'shelf-life']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees = process_content(\" \".join([sentence3, title3]), stopwords, tags)\n",
    "print title3, \"\\n\"\n",
    "print sentence3, \"\\n\"\n",
    "print tags3\n",
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam = \" \".join(process_content(\" \".join([sentence1, title1]), stopwords, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ham = \" \".join(list(csv.tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chocolate</th>\n",
       "      <th>bit</th>\n",
       "      <th>impact</th>\n",
       "      <th>syrup</th>\n",
       "      <th>dough</th>\n",
       "      <th>ratio</th>\n",
       "      <th>chip</th>\n",
       "      <th>sugar</th>\n",
       "      <th>maple</th>\n",
       "      <th>brown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>0.500773</td>\n",
       "      <td>0.351909</td>\n",
       "      <td>0.351909</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "      <td>0.250386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>0.016518</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.000621</td>\n",
       "      <td>0.015133</td>\n",
       "      <td>0.000668</td>\n",
       "      <td>0.001146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      chocolate       bit    impact     syrup     dough     ratio      chip  \\\n",
       "spam   0.500773  0.351909  0.351909  0.250386  0.250386  0.250386  0.250386   \n",
       "ham    0.016518  0.000000  0.000000  0.003819  0.013319  0.001193  0.000621   \n",
       "\n",
       "         sugar     maple     brown  \n",
       "spam  0.250386  0.250386  0.250386  \n",
       "ham   0.015133  0.000668  0.001146  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tvec = TfidfVectorizer(stop_words='english')\n",
    "tvec.fit([spam, ham])\n",
    "\n",
    "df  = pd.DataFrame(tvec.transform([spam, ham]).todense(),\n",
    "                   columns=tvec.get_feature_names(),\n",
    "                   index=['spam', 'ham'])\n",
    "\n",
    "df.transpose().sort_values('spam', ascending=False).head(10).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cooking = csv[(csv.file_name == 'cooking')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "other_topics = csv[(csv.file_name != 'cooking')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-39f5ed5faa22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     csv.loc[i, 'gen_tag'] = process_content(\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         stopwords, tags)\n\u001b[0m",
      "\u001b[0;32m/home/ali/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_setitem_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ali/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    290\u001b[0m                         new_indexer = convert_from_missing_indexer_tuple(\n\u001b[1;32m    291\u001b[0m                             indexer, self.obj.axes)\n\u001b[0;32m--> 292\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_indexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ali/anaconda2/lib/python2.7/site-packages/pandas/core/indexing.pyc\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m                         raise ValueError('Must have equal len keys and value '\n\u001b[0m\u001b[1;32m    528\u001b[0m                                          'when setting with an iterable')\n\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "csv['gen_tagg'] = None\n",
    "for i in range(len(csv)):\n",
    "    csv.loc[i, 'gen_tag'] = process_content(\" \".join([csv.loc[i, 'content'], csv.loc[i, 'title']]),\n",
    "        stopwords, tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
